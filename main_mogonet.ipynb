{"cells":[{"cell_type":"code","source":["## to access the google drive with the google account\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UW1nK5BcLQYN","executionInfo":{"status":"ok","timestamp":1666232181423,"user_tz":300,"elapsed":17351,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}},"outputId":"6d1cdd11-a4ed-4f5c-ab9f-7f839f8d85e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/MOGONET/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13yTh8HWLwQV","executionInfo":{"status":"ok","timestamp":1666232422501,"user_tz":300,"elapsed":183,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}},"outputId":"67f8125a-177d-4db5-c2cc-7e6d253bd02b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/MOGONET\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZFlacDiKuNW","executionInfo":{"status":"ok","timestamp":1666232504490,"user_tz":300,"elapsed":78474,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}},"outputId":"1f961f7f-5865-4e0e-d018-7c3cb4731054"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Pretrain GCNs...\n","\n","Training...\n","\n","Test: Epoch 0\n","Test ACC: 0.519\n","Test F1: 0.683\n","Test AUC: 0.159\n","\n","\n","Test: Epoch 50\n","Test ACC: 0.528\n","Test F1: 0.688\n","Test AUC: 0.661\n","\n","\n","Test: Epoch 100\n","Test ACC: 0.670\n","Test F1: 0.720\n","Test AUC: 0.797\n","\n","\n","Test: Epoch 150\n","Test ACC: 0.745\n","Test F1: 0.769\n","Test AUC: 0.872\n","\n","\n","Test: Epoch 200\n","Test ACC: 0.783\n","Test F1: 0.796\n","Test AUC: 0.887\n","\n","\n","Test: Epoch 250\n","Test ACC: 0.830\n","Test F1: 0.824\n","Test AUC: 0.885\n","\n","\n","Test: Epoch 300\n","Test ACC: 0.821\n","Test F1: 0.812\n","Test AUC: 0.899\n","\n","\n","Test: Epoch 350\n","Test ACC: 0.811\n","Test F1: 0.796\n","Test AUC: 0.897\n","\n","\n","Test: Epoch 400\n","Test ACC: 0.840\n","Test F1: 0.841\n","Test AUC: 0.906\n","\n","\n","Test: Epoch 450\n","Test ACC: 0.811\n","Test F1: 0.804\n","Test AUC: 0.894\n","\n","\n","Test: Epoch 500\n","Test ACC: 0.783\n","Test F1: 0.768\n","Test AUC: 0.882\n","\n","\n","Test: Epoch 550\n","Test ACC: 0.840\n","Test F1: 0.835\n","Test AUC: 0.899\n","\n","\n","Test: Epoch 600\n","Test ACC: 0.802\n","Test F1: 0.788\n","Test AUC: 0.889\n","\n","\n","Test: Epoch 650\n","Test ACC: 0.849\n","Test F1: 0.843\n","Test AUC: 0.892\n","\n","\n","Test: Epoch 700\n","Test ACC: 0.792\n","Test F1: 0.771\n","Test AUC: 0.885\n","\n","\n","Test: Epoch 750\n","Test ACC: 0.811\n","Test F1: 0.800\n","Test AUC: 0.889\n","\n","\n","Test: Epoch 800\n","Test ACC: 0.821\n","Test F1: 0.812\n","Test AUC: 0.872\n","\n","\n","Test: Epoch 850\n","Test ACC: 0.830\n","Test F1: 0.827\n","Test AUC: 0.889\n","\n","\n","Test: Epoch 900\n","Test ACC: 0.821\n","Test F1: 0.819\n","Test AUC: 0.889\n","\n","\n","Test: Epoch 950\n","Test ACC: 0.792\n","Test F1: 0.804\n","Test AUC: 0.886\n","\n","\n","Test: Epoch 1000\n","Test ACC: 0.830\n","Test F1: 0.827\n","Test AUC: 0.886\n","\n","\n","Test: Epoch 1050\n","Test ACC: 0.774\n","Test F1: 0.786\n","Test AUC: 0.895\n","\n","\n","Test: Epoch 1100\n","Test ACC: 0.830\n","Test F1: 0.820\n","Test AUC: 0.881\n","\n","\n","Test: Epoch 1150\n","Test ACC: 0.821\n","Test F1: 0.816\n","Test AUC: 0.874\n","\n","\n","Test: Epoch 1200\n","Test ACC: 0.821\n","Test F1: 0.822\n","Test AUC: 0.883\n","\n","\n","Test: Epoch 1250\n","Test ACC: 0.792\n","Test F1: 0.766\n","Test AUC: 0.874\n","\n","\n","Test: Epoch 1300\n","Test ACC: 0.830\n","Test F1: 0.824\n","Test AUC: 0.880\n","\n","\n","Test: Epoch 1350\n","Test ACC: 0.783\n","Test F1: 0.803\n","Test AUC: 0.876\n","\n","\n","Test: Epoch 1400\n","Test ACC: 0.830\n","Test F1: 0.827\n","Test AUC: 0.881\n","\n","\n","Test: Epoch 1450\n","Test ACC: 0.821\n","Test F1: 0.832\n","Test AUC: 0.892\n","\n","\n","Test: Epoch 1500\n","Test ACC: 0.821\n","Test F1: 0.812\n","Test AUC: 0.868\n","\n","\n","Test: Epoch 1550\n","Test ACC: 0.802\n","Test F1: 0.800\n","Test AUC: 0.866\n","\n","\n","Test: Epoch 1600\n","Test ACC: 0.811\n","Test F1: 0.818\n","Test AUC: 0.890\n","\n","\n","Test: Epoch 1650\n","Test ACC: 0.792\n","Test F1: 0.796\n","Test AUC: 0.863\n","\n","\n","Test: Epoch 1700\n","Test ACC: 0.783\n","Test F1: 0.803\n","Test AUC: 0.890\n","\n","\n","Test: Epoch 1750\n","Test ACC: 0.802\n","Test F1: 0.792\n","Test AUC: 0.871\n","\n","\n","Test: Epoch 1800\n","Test ACC: 0.764\n","Test F1: 0.779\n","Test AUC: 0.854\n","\n","\n","Test: Epoch 1850\n","Test ACC: 0.830\n","Test F1: 0.820\n","Test AUC: 0.883\n","\n","\n","Test: Epoch 1900\n","Test ACC: 0.821\n","Test F1: 0.822\n","Test AUC: 0.867\n","\n","\n","Test: Epoch 1950\n","Test ACC: 0.811\n","Test F1: 0.815\n","Test AUC: 0.883\n","\n","\n","Test: Epoch 2000\n","Test ACC: 0.840\n","Test F1: 0.841\n","Test AUC: 0.874\n","\n","\n","Test: Epoch 2050\n","Test ACC: 0.792\n","Test F1: 0.792\n","Test AUC: 0.864\n","\n","\n","Test: Epoch 2100\n","Test ACC: 0.774\n","Test F1: 0.782\n","Test AUC: 0.876\n","\n","\n","Test: Epoch 2150\n","Test ACC: 0.802\n","Test F1: 0.792\n","Test AUC: 0.865\n","\n","\n","Test: Epoch 2200\n","Test ACC: 0.840\n","Test F1: 0.841\n","Test AUC: 0.878\n","\n","\n","Test: Epoch 2250\n","Test ACC: 0.745\n","Test F1: 0.777\n","Test AUC: 0.876\n","\n","\n","Test: Epoch 2300\n","Test ACC: 0.811\n","Test F1: 0.811\n","Test AUC: 0.864\n","\n","\n","Test: Epoch 2350\n","Test ACC: 0.802\n","Test F1: 0.796\n","Test AUC: 0.867\n","\n","\n","Test: Epoch 2400\n","Test ACC: 0.792\n","Test F1: 0.780\n","Test AUC: 0.860\n","\n","\n","Test: Epoch 2450\n","Test ACC: 0.840\n","Test F1: 0.835\n","Test AUC: 0.874\n","\n","\n","Test: Epoch 2500\n","Test ACC: 0.821\n","Test F1: 0.829\n","Test AUC: 0.870\n","\n"]}],"source":["\"\"\" Example for MOGONET classification\n","\"\"\"\n","import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","import torch\n","import torch.nn.functional as F\n","from models import init_model_dict, init_optim\n","from utils import one_hot_tensor, cal_sample_weight, gen_adj_mat_tensor, gen_test_adj_mat_tensor, cal_adj_mat_parameter\n","\n","data_folder = 'BRCA'\n","view_list = [1,2,3]\n","num_epoch_pretrain = 500\n","num_epoch = 2500\n","lr_e_pretrain = 1e-3\n","lr_e = 5e-4\n","lr_c = 1e-3\n","\n","if data_folder == 'ROSMAP':\n","    num_class = 2\n","if data_folder == 'BRCA':\n","    num_class = 5\n","\n","\n","\n","root_path = '/content/drive/My Drive/Colab Notebooks/MOGONET/'\n","\n","\n","cuda = True if torch.cuda.is_available() else False\n","\n","\n","def prepare_trte_data(data_folder, view_list):\n","    num_view = len(view_list)\n","    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n","    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n","    labels_tr = labels_tr.astype(int)\n","    labels_te = labels_te.astype(int)\n","    data_tr_list = []\n","    data_te_list = []\n","    for i in view_list:\n","        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','))\n","        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=','))\n","    num_tr = data_tr_list[0].shape[0]\n","    num_te = data_te_list[0].shape[0]\n","    data_mat_list = []\n","    for i in range(num_view):\n","        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n","    data_tensor_list = []\n","    for i in range(len(data_mat_list)):\n","        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n","        if cuda:\n","            data_tensor_list[i] = data_tensor_list[i].cuda()\n","    idx_dict = {}\n","    idx_dict[\"tr\"] = list(range(num_tr))\n","    idx_dict[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n","    data_train_list = []\n","    data_all_list = []\n","    for i in range(len(data_tensor_list)):\n","        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n","        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n","                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n","    labels = np.concatenate((labels_tr, labels_te))\n","    \n","    return data_train_list, data_all_list, idx_dict, labels\n","\n","\n","def gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter):\n","    adj_metric = \"cosine\" # cosine distance\n","    adj_train_list = []\n","    adj_test_list = []\n","    for i in range(len(data_tr_list)):\n","        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n","        adj_train_list.append(gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric))\n","        adj_test_list.append(gen_test_adj_mat_tensor(data_trte_list[i], trte_idx, adj_parameter_adaptive, adj_metric))\n","    \n","    return adj_train_list, adj_test_list\n","\n","\n","def train_epoch(data_list, adj_list, label, one_hot_label, sample_weight, model_dict, optim_dict, train_VCDN=True):\n","    loss_dict = {}\n","    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n","    for m in model_dict:\n","        model_dict[m].train()    \n","    num_view = len(data_list)\n","    for i in range(num_view):\n","        optim_dict[\"C{:}\".format(i+1)].zero_grad()\n","        ci_loss = 0\n","        ci = model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i]))\n","        ci_loss = torch.mean(torch.mul(criterion(ci, label),sample_weight))\n","        ci_loss.backward()\n","        optim_dict[\"C{:}\".format(i+1)].step()\n","        loss_dict[\"C{:}\".format(i+1)] = ci_loss.detach().cpu().numpy().item()\n","    if train_VCDN and num_view >= 2:\n","        optim_dict[\"C\"].zero_grad()\n","        c_loss = 0\n","        ci_list = []\n","        for i in range(num_view):\n","            ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n","        c = model_dict[\"C\"](ci_list)    \n","        c_loss = torch.mean(torch.mul(criterion(c, label),sample_weight))\n","        c_loss.backward()\n","        optim_dict[\"C\"].step()\n","        loss_dict[\"C\"] = c_loss.detach().cpu().numpy().item()\n","    \n","    return loss_dict\n","    \n","\n","def test_epoch(data_list, adj_list, te_idx, model_dict):\n","    for m in model_dict:\n","        model_dict[m].eval()\n","    num_view = len(data_list)\n","    ci_list = []\n","    for i in range(num_view):\n","        ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n","    if num_view >= 2:\n","        c = model_dict[\"C\"](ci_list)    \n","    else:\n","        c = ci_list[0]\n","    c = c[te_idx,:]\n","    prob = F.softmax(c, dim=1).data.cpu().numpy()\n","    \n","    return prob\n","\n","\n","\n","test_inverval = 50\n","num_view = len(view_list)\n","dim_hvcdn = pow(num_class,num_view)\n","if data_folder == 'ROSMAP':\n","    adj_parameter = 2\n","    dim_he_list = [200,200,100]\n","if data_folder == 'BRCA':\n","    adj_parameter = 10\n","    dim_he_list = [400,400,200]\n","data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(root_path+data_folder, view_list)\n","labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx[\"tr\"]])\n","onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)\n","sample_weight_tr = cal_sample_weight(labels_trte[trte_idx[\"tr\"]], num_class)\n","sample_weight_tr = torch.FloatTensor(sample_weight_tr)\n","if cuda:\n","    labels_tr_tensor = labels_tr_tensor.cuda()\n","    onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()\n","    sample_weight_tr = sample_weight_tr.cuda()\n","adj_tr_list, adj_te_list = gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter)\n","dim_list = [x.shape[1] for x in data_tr_list]\n","model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)\n","for m in model_dict:\n","    if cuda:\n","        model_dict[m].cuda()\n","\n","print(\"\\nPretrain GCNs...\")\n","optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)\n","for epoch in range(num_epoch_pretrain):\n","    train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n","                onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_VCDN=False)\n","print(\"\\nTraining...\")\n","optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)\n","for epoch in range(num_epoch+1):\n","    train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n","                onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict)\n","    if epoch % test_inverval == 0:\n","        te_prob = test_epoch(data_trte_list, adj_te_list, trte_idx[\"te\"], model_dict)\n","        print(\"\\nTest: Epoch {:d}\".format(epoch))\n","        if num_class == 2:\n","            print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n","            print(\"Test F1: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n","            print(\"Test AUC: {:.3f}\".format(roc_auc_score(labels_trte[trte_idx[\"te\"]], te_prob[:,1])))\n","        else:\n","            print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n","            print(\"Test F1 weighted: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='weighted')))\n","            print(\"Test F1 macro: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='macro')))\n","        print()\n","\n","\n","           "]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.13 ('py3torch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d38809b76120d20a1d3e1d897a4f47c1eaa6798af8e438a196de9dcce5e3189a"}},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}