{"cells":[{"cell_type":"code","source":["## to access the google drive with the google account\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8w6LAoa-pPS","executionInfo":{"status":"ok","timestamp":1667604054752,"user_tz":300,"elapsed":19535,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}},"outputId":"1270174b-f906-40d0-aa6f-22f5deb078d6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/MOGONET/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTMzIayv_R9v","executionInfo":{"status":"ok","timestamp":1667604060861,"user_tz":300,"elapsed":142,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}},"outputId":"16a1b8c7-2153-4253-98af-7937cf10c293"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/MOGONET\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YMYMRBmK-lDW","executionInfo":{"status":"ok","timestamp":1667604068497,"user_tz":300,"elapsed":5445,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}}},"outputs":[],"source":["\"\"\" Example for MOGONET classification\n","\"\"\"\n","from train_test import train_test\n","import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","import torch\n","import torch.nn.functional as F\n","from models import init_model_dict, init_optim\n","from utils import one_hot_tensor, cal_sample_weight, gen_adj_mat_tensor, gen_test_adj_mat_tensor, cal_adj_mat_parameter\n","from losses import edl_mse_loss, edl_digamma_loss, edl_log_loss, relu_evidence\n","\n","\n","data_folder = 'ROSMAP'\n","view_list = [1,2,3]\n","num_epoch_pretrain = 500\n","num_epoch = 2500\n","lr_e_pretrain = 1e-3\n","lr_e = 5e-4\n","lr_c = 1e-3\n","\n","if data_folder == 'ROSMAP':\n","    num_class = 2\n","if data_folder == 'BRCA':\n","    num_class = 5\n","\n","root_path = '/content/drive/My Drive/Colab Notebooks/MOGONET/'\n","\n","cuda = True if torch.cuda.is_available() else False\n","\n","\n","\n","def prepare_trte_data(data_folder, view_list):\n","    num_view = len(view_list)\n","    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n","    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n","    labels_tr = labels_tr.astype(int)\n","    labels_te = labels_te.astype(int)\n","    data_tr_list = []\n","    data_te_list = []\n","    for i in view_list:\n","        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','))\n","        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=','))\n","    num_tr = data_tr_list[0].shape[0]\n","    num_te = data_te_list[0].shape[0]\n","    data_mat_list = []\n","    for i in range(num_view):\n","        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n","    data_tensor_list = []\n","    for i in range(len(data_mat_list)):\n","        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n","        if cuda:\n","            data_tensor_list[i] = data_tensor_list[i].cuda()\n","    idx_dict = {}\n","    idx_dict[\"tr\"] = list(range(num_tr))\n","    idx_dict[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n","    data_train_list = []\n","    data_all_list = []\n","    for i in range(len(data_tensor_list)):\n","        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n","        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n","                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n","    labels = np.concatenate((labels_tr, labels_te))\n","    \n","    return data_train_list, data_all_list, idx_dict, labels\n","\n","\n","def gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter):\n","    adj_metric = \"cosine\" # cosine distance\n","    adj_train_list = []\n","    adj_test_list = []\n","    for i in range(len(data_tr_list)):\n","        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n","        adj_train_list.append(gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric))\n","        adj_test_list.append(gen_test_adj_mat_tensor(data_trte_list[i], trte_idx, adj_parameter_adaptive, adj_metric))\n","    \n","    return adj_train_list, adj_test_list\n","\n","\n","def one_hot_embedding(labels, num_classes=10):\n","    # Convert to One Hot Encoding\n","    y = torch.eye(num_classes)\n","    return y[labels]\n","\n","\n","def train_epoch(data_list, adj_list, label, one_hot_label, sample_weight, model_dict, optim_dict, train_VCDN=True):\n","    loss_dict = {}\n","    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n","\n","    ## a new evidential criterion is used for the last VCDN\n","    criterion_evl = edl_mse_loss\n","\n","    y = one_hot_embedding(label, num_class)\n","\n","    for m in model_dict:\n","        model_dict[m].train()    \n","    num_view = len(data_list)\n","    for i in range(num_view):\n","        optim_dict[\"C{:}\".format(i+1)].zero_grad()\n","        ci_loss = 0\n","        ci = model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i]))\n","\n","        # ci_loss = torch.mean(torch.mul(criterion_evl(ci, y.float(), num_epoch, num_class, 10),sample_weight))\n","\n","        ci_loss = torch.mean(torch.mul(criterion(ci, label),sample_weight))\n","        ci_loss.backward()\n","        optim_dict[\"C{:}\".format(i+1)].step()\n","        loss_dict[\"C{:}\".format(i+1)] = ci_loss.detach().cpu().numpy().item()\n","    if train_VCDN and num_view >= 2:\n","        optim_dict[\"C\"].zero_grad()\n","        c_loss = 0\n","        ci_list = []\n","        for i in range(num_view):\n","            ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n","        c = model_dict[\"C\"](ci_list)    \n","\n","        \n","        ## This step is to replace with standard criterion with a new one\n","\n","        # c_loss = torch.mean(torch.mul(criterion(c, label),sample_weight))\n","        c_loss = torch.mean(torch.mul(criterion_evl(c, y.float(), num_epoch, num_class, 10),sample_weight))\n","\n","        c_loss.backward()\n","        optim_dict[\"C\"].step()\n","        loss_dict[\"C\"] = c_loss.detach().cpu().numpy().item()\n","    \n","    return loss_dict\n","    \n","\n","def test_epoch(data_list, adj_list, te_idx, model_dict):\n","    for m in model_dict:\n","        model_dict[m].eval()\n","    num_view = len(data_list)\n","    ci_list = []\n","    for i in range(num_view):\n","        ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n","    if num_view >= 2:\n","        c = model_dict[\"C\"](ci_list)    \n","    else:\n","        c = ci_list[0]\n","    c = c[te_idx,:]\n","\n","    evidence = relu_evidence(c)\n","    alpha = evidence + 1\n","    u = num_class / torch.sum(alpha, dim=1, keepdim=True)\n","    prob = F.softmax(c, dim=1).data.cpu().numpy()\n","    \n","    return prob, u\n","\n","    "]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yuj0CR49-lDZ","executionInfo":{"status":"ok","timestamp":1667607892478,"user_tz":300,"elapsed":93774,"user":{"displayName":"Allan Z. Ding","userId":"12421824806550707843"}},"outputId":"2d53d760-8b28-4784-ce28-39531f46fc11"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Pretrain GCNs...\n","\n","Training...\n","\n","Test: Epoch 0\n","Test ACC: 0.481\n","Test F1: 0.000\n","Test AUC: 0.167\n","\n","\n","Test: Epoch 50\n","Test ACC: 0.528\n","Test F1: 0.167\n","Test AUC: 0.594\n","\n","\n","Test: Epoch 100\n","Test ACC: 0.519\n","Test F1: 0.136\n","Test AUC: 0.706\n","\n","\n","Test: Epoch 150\n","Test ACC: 0.528\n","Test F1: 0.167\n","Test AUC: 0.802\n","\n","\n","Test: Epoch 200\n","Test ACC: 0.519\n","Test F1: 0.136\n","Test AUC: 0.795\n","\n","\n","Test: Epoch 250\n","Test ACC: 0.528\n","Test F1: 0.167\n","Test AUC: 0.846\n","\n","\n","Test: Epoch 300\n","Test ACC: 0.538\n","Test F1: 0.197\n","Test AUC: 0.872\n","\n","\n","Test: Epoch 350\n","Test ACC: 0.519\n","Test F1: 0.136\n","Test AUC: 0.846\n","\n","\n","Test: Epoch 400\n","Test ACC: 0.538\n","Test F1: 0.197\n","Test AUC: 0.878\n","\n","\n","Test: Epoch 450\n","Test ACC: 0.538\n","Test F1: 0.197\n","Test AUC: 0.875\n","\n","\n","Test: Epoch 500\n","Test ACC: 0.575\n","Test F1: 0.308\n","Test AUC: 0.883\n","\n","\n","Test: Epoch 550\n","Test ACC: 0.585\n","Test F1: 0.333\n","Test AUC: 0.870\n","\n","\n","Test: Epoch 600\n","Test ACC: 0.604\n","Test F1: 0.400\n","Test AUC: 0.877\n","\n","\n","Test: Epoch 650\n","Test ACC: 0.632\n","Test F1: 0.466\n","Test AUC: 0.858\n","\n","\n","Test: Epoch 700\n","Test ACC: 0.736\n","Test F1: 0.667\n","Test AUC: 0.884\n","\n","\n","Test: Epoch 750\n","Test ACC: 0.736\n","Test F1: 0.667\n","Test AUC: 0.880\n","\n","\n","Test: Epoch 800\n","Test ACC: 0.745\n","Test F1: 0.682\n","Test AUC: 0.884\n","\n","\n","Test: Epoch 850\n","Test ACC: 0.783\n","Test F1: 0.763\n","Test AUC: 0.873\n","\n","\n","Test: Epoch 900\n","Test ACC: 0.811\n","Test F1: 0.783\n","Test AUC: 0.875\n","\n","\n","Test: Epoch 950\n","Test ACC: 0.802\n","Test F1: 0.784\n","Test AUC: 0.884\n","\n","\n","Test: Epoch 1000\n","Test ACC: 0.830\n","Test F1: 0.820\n","Test AUC: 0.884\n","\n","\n","Test: Epoch 1050\n","Test ACC: 0.802\n","Test F1: 0.784\n","Test AUC: 0.886\n","\n","\n","Test: Epoch 1100\n","Test ACC: 0.802\n","Test F1: 0.784\n","Test AUC: 0.866\n","\n","\n","Test: Epoch 1150\n","Test ACC: 0.783\n","Test F1: 0.768\n","Test AUC: 0.881\n","\n","\n","Test: Epoch 1200\n","Test ACC: 0.802\n","Test F1: 0.788\n","Test AUC: 0.869\n","\n","\n","Test: Epoch 1250\n","Test ACC: 0.811\n","Test F1: 0.821\n","Test AUC: 0.881\n","\n","\n","Test: Epoch 1300\n","Test ACC: 0.811\n","Test F1: 0.811\n","Test AUC: 0.883\n","\n","\n","Test: Epoch 1350\n","Test ACC: 0.774\n","Test F1: 0.800\n","Test AUC: 0.886\n","\n","\n","Test: Epoch 1400\n","Test ACC: 0.830\n","Test F1: 0.824\n","Test AUC: 0.878\n","\n","\n","Test: Epoch 1450\n","Test ACC: 0.792\n","Test F1: 0.771\n","Test AUC: 0.863\n","\n","\n","Test: Epoch 1500\n","Test ACC: 0.783\n","Test F1: 0.772\n","Test AUC: 0.866\n","\n","\n","Test: Epoch 1550\n","Test ACC: 0.811\n","Test F1: 0.800\n","Test AUC: 0.881\n","\n","\n","Test: Epoch 1600\n","Test ACC: 0.821\n","Test F1: 0.804\n","Test AUC: 0.876\n","\n","\n","Test: Epoch 1650\n","Test ACC: 0.802\n","Test F1: 0.779\n","Test AUC: 0.867\n","\n","\n","Test: Epoch 1700\n","Test ACC: 0.821\n","Test F1: 0.808\n","Test AUC: 0.878\n","\n","\n","Test: Epoch 1750\n","Test ACC: 0.830\n","Test F1: 0.816\n","Test AUC: 0.873\n","\n","\n","Test: Epoch 1800\n","Test ACC: 0.783\n","Test F1: 0.785\n","Test AUC: 0.869\n","\n","\n","Test: Epoch 1850\n","Test ACC: 0.774\n","Test F1: 0.782\n","Test AUC: 0.858\n","\n","\n","Test: Epoch 1900\n","Test ACC: 0.811\n","Test F1: 0.808\n","Test AUC: 0.880\n","\n","\n","Test: Epoch 1950\n","Test ACC: 0.783\n","Test F1: 0.763\n","Test AUC: 0.861\n","\n","\n","Test: Epoch 2000\n","Test ACC: 0.802\n","Test F1: 0.800\n","Test AUC: 0.874\n","\n","\n","Test: Epoch 2050\n","Test ACC: 0.811\n","Test F1: 0.808\n","Test AUC: 0.869\n","\n","\n","Test: Epoch 2100\n","Test ACC: 0.783\n","Test F1: 0.772\n","Test AUC: 0.865\n","\n","\n","Test: Epoch 2150\n","Test ACC: 0.821\n","Test F1: 0.829\n","Test AUC: 0.878\n","\n","\n","Test: Epoch 2200\n","Test ACC: 0.840\n","Test F1: 0.832\n","Test AUC: 0.873\n","\n","\n","Test: Epoch 2250\n","Test ACC: 0.802\n","Test F1: 0.804\n","Test AUC: 0.865\n","\n","\n","Test: Epoch 2300\n","Test ACC: 0.811\n","Test F1: 0.811\n","Test AUC: 0.863\n","\n","\n","Test: Epoch 2350\n","Test ACC: 0.792\n","Test F1: 0.788\n","Test AUC: 0.865\n","\n","\n","Test: Epoch 2400\n","Test ACC: 0.821\n","Test F1: 0.829\n","Test AUC: 0.880\n","\n","\n","Test: Epoch 2450\n","Test ACC: 0.811\n","Test F1: 0.808\n","Test AUC: 0.865\n","\n","\n","Test: Epoch 2500\n","Test ACC: 0.802\n","Test F1: 0.807\n","Test AUC: 0.872\n","\n"]}],"source":["\n","## the entrance of the MOGONET\n","\n","test_inverval = 50\n","num_view = len(view_list)\n","dim_hvcdn = pow(num_class,num_view)\n","if data_folder == 'ROSMAP':\n","    adj_parameter = 2\n","    dim_he_list = [200,200,100]\n","if data_folder == 'BRCA':\n","    adj_parameter = 10\n","    dim_he_list = [400,400,200]\n","    \n","data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(root_path+data_folder, view_list)\n","labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx[\"tr\"]])\n","onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)\n","sample_weight_tr = cal_sample_weight(labels_trte[trte_idx[\"tr\"]], num_class)\n","sample_weight_tr = torch.FloatTensor(sample_weight_tr)\n","if cuda:\n","    labels_tr_tensor = labels_tr_tensor.cuda()\n","    onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()\n","    sample_weight_tr = sample_weight_tr.cuda()\n","adj_tr_list, adj_te_list = gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter)\n","dim_list = [x.shape[1] for x in data_tr_list]\n","model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)\n","for m in model_dict:\n","    if cuda:\n","        model_dict[m].cuda()\n","\n","print(\"\\nPretrain GCNs...\")\n","optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)\n","for epoch in range(num_epoch_pretrain):\n","    train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n","                onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_VCDN=False)\n","print(\"\\nTraining...\")\n","optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)\n","for epoch in range(num_epoch+1):\n","    train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n","                onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict)\n","    if epoch % test_inverval == 0:\n","        te_prob, te_uncertainty = test_epoch(data_trte_list, adj_te_list, trte_idx[\"te\"], model_dict)\n","        print(\"\\nTest: Epoch {:d}\".format(epoch))\n","        if num_class == 2:\n","            print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n","            print(\"Test F1: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n","            print(\"Test AUC: {:.3f}\".format(roc_auc_score(labels_trte[trte_idx[\"te\"]], te_prob[:,1])))\n","        else:\n","            print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n","            print(\"Test F1 weighted: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='weighted')))\n","            print(\"Test F1 macro: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='macro')))\n","        print()\n","\n","      "]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.13 ('py3torch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d38809b76120d20a1d3e1d897a4f47c1eaa6798af8e438a196de9dcce5e3189a"}},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}